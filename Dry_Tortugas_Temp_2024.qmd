---
title: "Dry_Tortugas_Temp_2024"
author: "Maddy Enda"
format: html
editor: visual
---

# Temperature Data 2026 Update: Dry Tortugas National Park 2024

### Author- Madison Enda, January 28th, 2026

### Contact- madison.enda\@myfwc.com

## Overview:

-   In this script, we will be combining the site specific temperature data sets from 2024 into master lists, aggregating them into a combined csv, and appending that to the dry_tortugas_master_2025.csv.

-   This data was pulled from the FWRI Coral Research Program's shared temperature data drive, and contain temperature data from the individual sites for each year, recorded once every hour.The final master file will be added to the new 2026 database. For ease of access (and to avoid syncing with SharePoint which proved to take some time),the folders were downloaded manually to my device, and thus my file path is unique to my device.

## Load libraries

```{r}
# Install librarian for multiple packages and quick readability
# install.packages("librarian")

# Using librarian::shelf to import many libraries at once
librarian::shelf(tidyverse, dplyr, here, purrr, hms, lubridate)
```

## Use function and code from previous files (Dry_Tortugas_Temp_2022-2023.qmd) to load and clean data

```{r}
# Function to fix a single malformed CSV
fix_csv <- function(file_path, n_cols = 6, sep = ",") {

  df <- read_csv(
    file_path,
    col_names = FALSE,
    show_col_types = FALSE
  )

  names(df) <- "raw_data"

  df %>%
    separate(
      col = raw_data,
      into = paste0("col", 1:n_cols),
      sep = sep,
      fill = "right",
      extra = "drop",
      convert = TRUE
    ) %>%
    mutate(source_file = basename(file_path))
}

# Get all CSV files in the folder
files <- list.files(
  path = "C:/Users/Madison.enda/Desktop/Temp_Data/2024",
  pattern = "\\.csv$",
  full.names = TRUE
)

# Fix each CSV, then combine into one data frame
dt_temp_2024 <- map_dfr(files, fix_csv)

# Remove the first two rows
dt_temp_2024 <- dt_temp_2024 %>% 
  slice(-(1:2))

# Use case_when to change the csv file names in source_file into site_name
dt_temp_2024 <- dt_temp_2024 %>%
mutate(site_name = case_when(
    source_file == "BCR_Off1_23-24.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_23-24.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off1_23-24.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_Off1_23-24.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_Off2_23-24.csv"     ~ "Mayer's Peak",
    source_file == "Maze_Off1_23-24.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_23-24.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_23-24.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_23-24.csv" ~ "Temptation",
    source_file == "Texas_In2_23-24.csv"       ~ "Texas Rock",
    source_file == "WhiteShoal_Off3_23-24.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Drop extra columns
dt_temp_2024 <- dt_temp_2024 %>% 
  select(-c(col4, col5, col6))

# Rename columns
dt_temp_2024 <- dt_temp_2024 %>%
  rename(
    observation_id = col1,
    date = col2,
    temp_F = col3
  )


# We will separate the dates out into date and time
dt_temp_2024 <- dt_temp_2024 %>%
  mutate(datetime = mdy_hms(date)) %>%
  mutate(
    date = as.Date(datetime),
    time = format(datetime, "%H:%M:%S")  # converts to 24-hour (military) time
  ) %>%
  select(-datetime)

# Move the time column back to it's original place
dt_temp_2024 <- dt_temp_2024 %>%
  select(1:2, time, everything())

# We will remove all 10 rows that have no temperature data (NA or empty)
dt_temp_2024 <- dt_temp_2024 %>%
  filter(!is.na(temp_F) & temp_F != "")

# Remove the # observations in the observation_id column (10 rows)
dt_temp_2024 <- dt_temp_2024 %>%
  filter(!grepl("[^0-9]", observation_id))

# Create the temperature column in Celsius
dt_temp_2024 <- dt_temp_2024 %>%
  mutate(temp_F = as.numeric(temp_F),
         temp_C = (temp_F - 32) / 1.8)
```

## Assess missing data and change data types

```{r}
# Look for NAs
colSums(is.na(dt_temp_2024))

# Check the data types of our columns
str(dt_temp_2024)
```

-   It seems like there are some names that did not get transferred from the source_file names. I will take a look at the NA's and determine where the new site or typo is.

```{r}
# Identify rows with NA for site_name
dt_2024_NAs <- dt_temp_2024 %>%
  filter(is.na(site_name))

# Find the file names that did not get turned into site_names
unique(dt_2024_NAs$source_file)
```

-   It seems like each of these csv files have different names for the locations, other than just the year. I will use the name of these locations as well for creating site names:

```{r}
# Use case_when to change the csv file names in source_file into site_name
dt_temp_2024 <- dt_temp_2024 %>%
mutate(site_name = case_when(
    source_file == "BlackCoralRock_Off2_23-24.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_23-24.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off4_23-24.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_In1_23-24.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_In1_23-24.csv"     ~ "Mayer's Peak",
    source_file == "Maze_In1_23-24.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_23-24.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_23-24.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_23-24.csv" ~ "Temptation",
    source_file == "Texas_Off3_23-24.csv"       ~ "Texas Rock",
     source_file == "WhiteShoal_Off3_23-24.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Check remaining NA values
colSums(is.na(dt_temp_2024))
```

-   Perfect! Now we can remove the source_file column and standardize our data types

```{r}
# Remove the source_file column using select()
dt_temp_2024 <- dt_temp_2024 %>%
  select(-source_file)
```

## Changing data types

```{r}
# Formatting the data set:

# Check data types for formatting
str(dt_temp_2024)

# Change the time to military time:
dt_temp_2024$time <- as_hms(dt_temp_2024$time)


# Set the site_id column as an integer
dt_temp_2024$observation_id <- as.integer(dt_temp_2024$observation_id)


# Check data types for formatting
str(dt_temp_2024)
```

## Write cleaned file to local device!

```{r}
# Write the file to the location where other master lists are hosted
write.csv(dt_temp_2024, "C:/Users/Madison.Enda/Desktop/Temp_Data/temp_dry_tortugas_2026_update/DRTO_2024_Master.csv")
```
