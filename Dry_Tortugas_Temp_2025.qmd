---
title: "Dry_Tortugas_Temp_2025"
author: "Maddy Enda"
format: html
editor: visual
---

# Temperature Data 2026 Update: Dry Tortugas National Park 2025

### Author- Madison Enda, January 28th, 2026

### Contact- madison.enda\@myfwc.com

## Overview:

-   In this script, we will be combining the site specific temperature data sets from 2025 into master lists, aggregating them into a combined csv, and appending that to the dry_tortugas_master_2025.csv.

-   This data was pulled from the FWRI Coral Research Program's shared temperature data drive, and contain temperature data from the individual sites for each year, recorded once every hour.The final master file will be added to the new 2026 database. For ease of access (and to avoid syncing with SharePoint which proved to take some time),the folders were downloaded manually to my device, and thus my file path is unique to my device.

## Load libraries

```{r}
# Install librarian for multiple packages and quick readability
# install.packages("librarian")

# Using librarian::shelf to import many libraries at once
librarian::shelf(tidyverse, dplyr, here, purrr, hms, lubridate)
```

## Use function and code from previous files (Dry_Tortugas_Temp_2022-2023.qmd) to load and clean data

```{r}
# Fix the 2025 data

# Function to fix a single malformed CSV
fix_csv <- function(file_path, n_cols = 6, sep = ",") {

  df <- read_csv(
    file_path,
    col_names = FALSE,
    show_col_types = FALSE
  )

  names(df) <- "raw_data"

  df %>%
    separate(
      col = raw_data,
      into = paste0("col", 1:n_cols),
      sep = sep,
      fill = "right",
      extra = "drop",
      convert = TRUE
    ) %>%
    mutate(source_file = basename(file_path))
}

# Get all CSV files in the folder
files <- list.files(
  path = "C:/Users/Madison.enda/Desktop/Temp_Data/DT",
  pattern = "\\.csv$",
  full.names = TRUE
)

# Fix each CSV, then combine into one data frame
dt_temp_2025 <- map_dfr(files, fix_csv)

# Remove the first two rows
dt_temp_2025 <- dt_temp_2025 %>% 
  slice(-(1:2))

# Use case_when to change the csv file names in source_file into site_name
dt_temp_2025 <- dt_temp_2025 %>%
mutate(site_name = case_when(
    source_file == "BCR_Off1_24-25.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_24-25.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off1_24-25.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_Off1_24-25.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_Off2_24-25.csv"     ~ "Mayer's Peak",
    source_file == "Maze_Off1_24-25.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_24-25.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_24-25.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_24-25.csv" ~ "Temptation",
    source_file == "Texas_In2_24-25.csv"       ~ "Texas Rock",
    source_file == "WhiteShoal_Off3_24-25.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Drop extra columns
dt_temp_2025 <- dt_temp_2025 %>% 
  select(-c(col4, col5, col6))

# Rename columns
dt_temp_2025 <- dt_temp_2025 %>%
  rename(
    observation_id = col1,
    date = col2,
    temp_F = col3
  )

# We will separate the dates out into date and time
dt_temp_2025 <- dt_temp_2025 %>%
  mutate(datetime = mdy_hms(date)) %>%
  mutate(
    date = as.Date(datetime),
    time = format(datetime, "%H:%M:%S")  # converts to 24-hour (military) time
  ) %>%
  select(-datetime)

# Move the time column back to it's original place
dt_temp_2025 <- dt_temp_2025 %>%
  select(1:2, time, everything())

# We will remove all 10 rows that have no temperature data (NA or empty)
dt_temp_2025 <- dt_temp_2025 %>%
  filter(!is.na(temp_F) & temp_F != "")

# Remove the # observations in the observation_id column (10 rows)
dt_temp_2025 <- dt_temp_2025 %>%
  filter(!grepl("[^0-9]", observation_id))

# Create the temperature column in Celsius
dt_temp_2025 <- dt_temp_2025 %>%
  mutate(temp_F = as.numeric(temp_F),
         temp_C = (temp_F - 32) / 1.8)
```

## Check for NA values (especially in the site_name column)

```{r}
# Look for NAs
colSums(is.na(dt_temp_2025))

# Check the data types of our columns
str(dt_temp_2025)
```

-   We have the same issue as before where we simply need to identify what the csv files were named as in some of the 2025 data in order to assign them to a site using case_when. I will use the same approach as last time, creating a data frame that has NAs in the site_name column and using len(unique()) and unique() to find the entries in the source_file column

```{r}
# Identify rows with NA for site_name
dt_2025_NAs <- dt_temp_2025 %>%
  filter(is.na(site_name))

# Find the file names that did not get turned into site_names
unique(dt_2025_NAs$source_file)
```

```{r}
# Use case_when to change the csv file names in source_file into site_name
dt_temp_2025 <- dt_temp_2025 %>%
mutate(site_name = case_when(
    source_file == "BlackCoralRock_Off2_24-25.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_24-25.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off4_24-25.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_Off1_24-25.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_In4_24-25.csv"     ~ "Mayer's Peak",
    source_file == "Maze_In2_24-25.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_24-25.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_24-25.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_24-25.csv" ~ "Temptation",
    source_file == "Texas_Off3_24-25.csv"       ~ "Texas Rock",
     source_file == "WhiteShoal_Off3_24-25.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Check remaining NA values
colSums(is.na(dt_temp_2025))
```

-   Excellent! Now we can get rid of the source_file column and continue on with our type cleaning

```{r}
# Remove the source_file column using select()
dt_temp_2025 <- dt_temp_2025 %>%
  select(-source_file)
```

## Changing data types

```{r}
# Formatting the data set:

# Check data types for formatting
str(dt_temp_2025)

# Change the time to military time:
dt_temp_2025$time <- as_hms(dt_temp_2025$time)


# Set the site_id column as an integer
dt_temp_2025$observation_id <- as.integer(dt_temp_2025$observation_id)
```

## Write cleaned file to local device!

```{r}
# Write the file to the location where other master lists are hosted
write.csv(dt_temp_2025, "C:/Users/Madison.Enda/Desktop/Temp_Data/temp_dry_tortugas_2026_update/DRTO_2025_Master.csv")
```
