---
title: "Florida_Keys_Temp_2023"
author: "Maddy"
format: html
editor: visual
---

# Temperature Data 2026 Update: Florida Keys National Marine Sanctuary

### Author- Madison Enda, February 5th, 2026

### Contact- madison.enda\@myfwc.com

## Overview:

-   In this script, we will be combining all 2023 temperature files from the Florida Key National Marine Sanctuary: pulling them off of the FWRI Coral Research Program's shared drive and creating an index to be used as our primary key for the 'Temperature' table in the upcoming database. For ease of access (and to avoid syncing with SharePoint which proved to take some time),the folder was downloaded manually to my device, and thus my file path is unique to my device.

-   This workflow will include general cleaning (standardizing naming conventions, removing superfluous data, etc.) and the final result will be uploaded to the shared drive once again, until permissions are received to migrate to a new platform.

## Import Libraries

```{r}
# Install librarian for multiple packages and quick readability
# install.packages("librarian")

# Using librarian::shelf to import many libraries at once
librarian::shelf(tidyverse, dplyr, here, purrr, hms, lubridate, stringr)
```


# Creating functionality for all 2022-2023 files
## Cleaning function:

```{r}
# Function to clean the files

# Lookup table for site names based on source_file
site_lookup <- tibble(
  source_file = c(
    "Admiral_22-23.csv",
    "Alligator_Deep_22-23.csv",
    "Alligator_Shallow_22-23.csv",
    "Burr_Fish_22-23.csv",
    "Carysfort_Deep_22-23.csv",
    "Cliff_Green_22-23.csv",
    "Conch_Deep_22-23.csv",
    "Conch_Shallow_22-23.csv",
    "Content_Keys_22-23.csv",
    "Dove_22-23.csv",
    "Dustan_Rocks_22-23.csv",
    "East_Sambo_Shallow_22-23.csv",
    "Eastern_Sambo_Deep_22-23.csv",
    "El_Radabob_22-23.csv",
    "Grecian_Rocks_22-23.csv",
    "Jaap_22-23.csv",
    "Long_Key_22-23.csv",
    "Looe_Deep_22-23.csv",
    "Looe_Shallow_22-23.csv",
    "Molasses_Deep_22-23.csv",
    "Molasses_Shallow_22-23.csv",
    "Porter_Patch_22-23.csv",
    "Rattlesnake_22-23.csv",
    "Rawa_22-23.csv",
    "Red_Dun_22-23.csv",
    "Rock_Key_Deep_22-23.csv",
    "Sand_Key_Deep_22-23.csv",
    "Sand_Key_Shallow_22-23.csv",
    "Smith_Shoal_22-23.csv",
    "Sombrero_Deep_22-23.csv",
    "Sombrero_Shallow_22-23.csv",
    "Tennessee_Deep_22-23.csv",
    "Thor_22-23.csv",
    "Turtle_22-23.csv",
    "Two_Patches_22-23.csv",
    "West_Sambo_Deep_22-23.csv",
    "West_Sambo_Shallow_22-23.csv",
    "West_Turtle_Shoal_22-23.csv",
    "West_Washerwoman_22-23.csv",
    "Western_Head_22-23.csv",
    "Wonderland_22-23.csv"
    ),
  site_name = c(
     "Admiral",
     "Alligator Deep",
     "Alligator Shallow",
     "Burr Fish",
     "Carysfort Deep",
     "Cliff Green",
     "Conch Deep",
     "Conch Shallow",
     "Content Keys",
     "Dove Key",
     "Dustan Rocks",
     "Eastern Sambo Deep",
     "Eastern Sambo Shallow",
     "El Radabob",
     "Grecian Rocks",
     "Jaap Reef",
     "Long Key",
     "Looe Key Deep",
     "Looe Key Shallow",
     "Molasses Deep",
     "Molasses Shallow",
     "Port Patch",
     "Rattlesnake",
     "Rawa Reef",
     "Red Dun Reef",
     "Rock Key Deep",
     "Sand Key Deep",
     "Sand Key Shallow",
     "Smith Shoal",
     "Sombrero Deep",
     "Sombrero Shallow",
     "Tennessee Deep",
     "Thor",
     "Turtle",
     "Two Patches",
     "Western Sambo Deep",
     "Western Sambo Shallow",
      "West Turtle Shoal",
     "West Washerwoman",
     "Western Head",
     "Wonderland"           
  )
)

# --- Function to clean a single CSV ---
clean_temp_csv <- function(file_path, n_cols = 6, sep = ",") {
  
  df <- read_csv(file_path, col_names = FALSE, show_col_types = FALSE) %>%
    setNames("raw_data") %>%
    separate(
      col = raw_data,
      into = paste0("col", 1:n_cols),
      sep = sep,
      fill = "right",
      extra = "drop",
      convert = TRUE
    ) %>%
    slice(-(1:2)) %>%                     # remove first two rows
    mutate(source_file = basename(file_path)) %>%
    select(col1, col2, col3, source_file) %>%
    rename(
      observation_id = col1,
      datetime_raw   = col2,
      temp_F         = col3
    ) %>%
    filter(!is.na(temp_F), temp_F != "") %>%
    filter(!grepl("[^0-9]", observation_id)) %>%
    mutate(
      # Parse date/time from the raw datetime column
      datetime = mdy_hms(datetime_raw),
      date     = as.Date(datetime),
      time     = as_hms(format(datetime, "%H:%M:%S")),
      temp_F   = as.numeric(temp_F),
      temp_C   = (temp_F - 32) / 1.8,
      observation_id = as.integer(observation_id)
    ) %>%
    left_join(site_lookup, by = "source_file") %>%
    select(-datetime_raw, -source_file) %>%
    select(observation_id, date, time, datetime, everything())
  
  return(df)
}
```
