---
title: "Trimming_Dry_Tortugas_temp_2022"
format:
  html:
    theme: default
---


# Cleaning the Dry Tortugas Temperature data: Trimming Each CSV

### Author: Maddy Enda
### Contact: madison.enda@myfwc.com
### Written: 01/30/2026


## Overview:

After compiling all of the years of temperature data in Dry Tortugas National Park (2006-2025), I found there were multiple entries for some locations at the same exact time. To get to the bottom of this mystery, we are going to trim any data that may have been recorded after the sensors were removed from the water.

The dates and times that each csv should be trimmed to are in a logger data file on the shared temperature drive for the FWRI Coral Research Program.

## Import libraries

```{r}
# Using librarian::shelf to import many libraries at once
librarian::shelf(tidyverse, dplyr, here, purrr, hms, lubridate, stringr)
```


## Import the Black Coral Reef csv file

```{r}
# Import just one file

# Function to fix a single malformed CSV 
fix_csv <- function(file_path, n_cols = 6, sep = ",") {

  df <- read_csv(
    file_path,
    col_names = FALSE,
    show_col_types = FALSE
  )

  names(df) <- "raw_data"

  df %>%
    separate(
      col = raw_data,
      into = paste0("col", 1:n_cols),
      sep = sep,
      fill = "right",
      extra = "drop",
      convert = TRUE
    ) %>%
    mutate(source_file = basename(file_path))
}

# ---- run on ONE file ----
file_path <- "C:/Users/Madison.enda/Desktop/Temp_Data/2023/BCR_Off1_22-23.csv"

BCR_Off1_22_23 <- fix_csv(file_path)
```
# Run through the cleaning code

```{r}
# Remove the first two rows
BCR_Off1_22_23 <- BCR_Off1_22_23 %>% 
  slice(-(1:2)) 

# Use case_when to change the csv file names in source_file into site_name
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
mutate(site_name = case_when(
    source_file == "BCR_Off1_22-23.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_22-23.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off1_22-23.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_Off1_22-23.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_Off2_22-23.csv"     ~ "Mayer's Peak",
    source_file == "Maze_Off1_22-23.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_22-23.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_22-23.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_22-23.csv" ~ "Temptation",
    source_file == "Texas_In2_22-23.csv"       ~ "Texas Rock",
    source_file == "WhiteShoal_Off3_22-23.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Drop extra columns
BCR_Off1_22_23 <- BCR_Off1_22_23 %>% 
  select(-c(col4, col5, col6))

# Rename columns
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  rename(
    observation_id = col1,
    date = col2,
    temp_F = col3
  )


# We will separate the dates out into date and time
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  mutate(datetime = mdy_hms(date)) %>%
  mutate(
    date = as.Date(datetime),
    time = format(datetime, "%H:%M:%S")  # converts to 24-hour (military) time
  ) %>%
  select(-datetime)

# Move the time column back to it's original place
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  select(1:2, time, everything())

# We will remove all 10 rows that have no temperature data (NA or empty)
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  filter(!is.na(temp_F) & temp_F != "")

# Remove the # observations in the observation_id column (10 rows)
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  filter(!grepl("[^0-9]", observation_id))

# Create the temperature column in Celsius
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  mutate(temp_F = as.numeric(temp_F),
         temp_C = (temp_F - 32) / 1.8)
```


## Assess missing data and change data types

```{r}
# Look for NAs
colSums(is.na(BCR_Off1_22_23))

# Check the data types of our columns
str(BCR_Off1_22_23)
```

-   It seems like there are some names that did not get transferred from the source_file names. I will take a look at the NA's and determine where the new site or typo is.

```{r}
# Identify rows with NA for site_name
missing_sites <- BCR_Off1_22_23 %>%
  filter(is.na(site_name))

# Find the file names that did not get turned into site_names
unique(missing_sites$source_file)
```

-   It seems like each of these csv files have different names for the locations, other than just the year. I will use the name of these locations as well for creating site names:

```{r}
# Use case_when to change the csv file names in source_file into site_name
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
mutate(site_name = case_when(
    source_file == "BCR_Off1_22-23.csv"        ~ "Black Coral Rock",
    source_file == "BirdKey_Off1_22-23.csv"    ~ "Bird Key Reef",
    source_file == "Davis_Off1_22-23.csv"      ~ "Davis Rock",
    source_file == "Loggerhead_Off1_22-23.csv" ~ "Loggerhead Patch",
    source_file == "Mayers_Off2_22-23.csv"     ~ "Mayer's Peak",
    source_file == "Maze_Off1_22-23.csv"       ~ "The Maze",
    source_file == "Palmata_Off2_22-23.csv"    ~ "Palmata Patch",
    source_file == "Prolifera_In2_22-23.csv"   ~ "Prolifera",
    source_file == "Temptation_Off2_22-23.csv" ~ "Temptation",
    source_file == "Texas_In2_22-23.csv"       ~ "Texas Rock",
    source_file == "WhiteShoal_Off3_22-23.csv" ~ "White Shoal",
    TRUE                                       ~ NA_character_  # fallback for any other file names
  ))

# Check remaining NA values
colSums(is.na(BCR_Off1_22_23))
```

-   Perfect! Now we can remove the source_file column and standardize our data types

```{r}
# Remove the source_file column using select()
BCR_Off1_22_23 <- BCR_Off1_22_23 %>%
  select(-source_file)
```

## Changing data types

```{r}
# Formatting the data set:

# Check data types for formatting
str(BCR_Off1_22_23)

# Change the time to military time:
BCR_Off1_22_23$time <- as_hms(BCR_Off1_22_23$time)


# Set the site_id column as an integer
BCR_Off1_22_23$observation_id <- as.integer(BCR_Off1_22_23$observation_id)


# Check data types for formatting
str(BCR_Off1_22_23)
```


____________________________________________________________________________________________________________________

# Creating functionality for all 2022-2023 files

```{r}
# Function to clean the files

# Lookup table for site names based on source_file
site_lookup <- tibble(
  source_file = c(
    "BCR_Off1_22-23.csv",
    "BirdKey_Off1_22-23.csv",
    "Davis_Off1_22-23.csv",
    "Loggerhead_Off1_22-23.csv",
    "Mayers_Off2_22-23.csv",
    "Maze_Off1_22-23.csv",
    "Palmata_Off2_22-23.csv",
    "Prolifera_In2_22-23.csv",
    "Temptation_Off2_22-23.csv",
    "Texas_In2_22-23.csv",
    "WhiteShoal_Off3_22-23.csv"
  ),
  site_name = c(
    "Black Coral Rock",
    "Bird Key Reef",
    "Davis Rock",
    "Loggerhead Patch",
    "Mayer's Peak",
    "The Maze",
    "Palmata Patch",
    "Prolifera",
    "Temptation",
    "Texas Rock",
    "White Shoal"
  )
)

# --- Function to clean a single CSV ---
clean_temp_csv <- function(file_path, n_cols = 6, sep = ",") {
  
  # Read CSV and separate columns
  df <- read_csv(file_path, col_names = FALSE, show_col_types = FALSE) %>%
    setNames("raw_data") %>%
    separate(
      col = raw_data,
      into = paste0("col", 1:n_cols),
      sep = sep,
      fill = "right",
      extra = "drop",
      convert = TRUE
    ) %>%
    slice(-(1:2)) %>%                     # remove first two rows
    mutate(source_file = basename(file_path)) %>%
    select(col1, col2, col3, source_file) %>%
    rename(
      observation_id = col1,
      datetime_raw   = col2,
      temp_F         = col3
    ) %>%
    filter(!is.na(temp_F), temp_F != "") %>%
    filter(!grepl("[^0-9]", observation_id)) %>%
    mutate(
      datetime = mdy_hms(datetime_raw),
      date     = as.Date(datetime),
      time     = as_hms(format(datetime, "%H:%M:%S")),
      temp_F   = as.numeric(temp_F),
      temp_C   = (temp_F - 32) / 1.8,
      observation_id = as.integer(observation_id)
    ) %>%
    left_join(site_lookup, by = "source_file") %>%
    select(-datetime_raw, -source_file) %>%
    select(observation_id, date, time, everything())
  
  return(df)
}

```










# Trim first file: Black Coral Reef

```{r}
# Let's unpack one file, trim it, and then automate our process
# I will first create a data frame with the data from the Temp Logger Metadata File

# Create vectors of the data 
site_id <- c(82,83,28,46,45,27,42,43,44,29,41)

site_name <- c("Bird Key","Black Coral Rock","Davis","Loggerhead","Mayers Peak","Maze","Palmata Patch","Prolifera Patch", "Temptation Rock","Texas Rock","White Shoal")

location <- c("Off 1","Off 1","Off 1","Off 1","Off 2","Off 1","Off 2","In 2","Off 2","In 2","Off 3")

logger_sn <- c(20868472,20364170,20868470,21151646,20668467,21151660,20606816,20423767,20868479,21151651,20423765)


deployment_date <- as.Date(c(
  "2022-08-14","2022-08-13","2022-08-12","2022-08-15","2022-08-11",
  "2022-08-11","2022-08-15","2022-08-15","2022-08-11","2022-08-12","2022-08-12"
))

deployment_time <- hms::as_hms(c(
  "11:00:00","08:30:00","11:00:00","15:00:00","10:00:00",
  "14:00:00","11:35:00","09:00:00","17:30:00","08:25:00","13:57:00"
))

retrieval_date <- as.Date(c(
  "2023-08-09","2023-08-11","2023-08-12","2023-08-10","2023-08-10",
  "2023-08-10","2023-08-09","2023-08-09","2023-08-11","2023-08-08","2023-08-10"
))

retrieval_time <- hms::as_hms(c(
  "11:06:00","09:00:00","08:50:00","09:13:00","13:43:00",
  "16:44:00","11:06:00","09:07:00","14:15:00","14:03:00","10:21:00"
))

# Create the data frame from the vectors
date_ranges_22_23 <- data.frame(
  site_id        = site_id,
  site_name   = site_name,
  location     = location,
  logger_sn = logger_sn,
  deployment_date = deployment_date,
  deployment_time = deployment_time,
  retrieval_date = retrieval_date,
  retrieval_time = retrieval_time,
  stringsAsFactors = FALSE
)
```



```{r}
# Create a date window to use for the trimming
date_ranges_22_23 <- date_ranges_22_23 %>%
  mutate(
    deploy_dt  = as.POSIXct(deployment_date) + deployment_time,
    retrieve_dt = as.POSIXct(retrieval_date) + retrieval_time
  )
```

